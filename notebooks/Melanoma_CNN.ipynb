{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1yrrUYqhH6S"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/compomics/ML-course-VIB-2024/blob/master/notebooks/Melanoma_CNN.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBFXQGKYUc4X"
      },
      "source": [
        "*Disclaimer: this notebook extends the analysis of the [Flowers Image Classification notebook](https://www.tensorflow.org/tutorials/images/classification) to Malanoma images.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Skin lesion image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RDZ0jwOCTM-"
      },
      "source": [
        "The data will be downloaded from the [\n",
        "ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection challenge\n",
        "](https://challenge2018.isic-archive.com/) [1].\n",
        "\n",
        "The goal of this recurring challenge is to help participants develop image analysis tools to enable the automated diagnosis of melanoma from dermoscopic images.\n",
        "\n",
        "The lesion images come from the HAM10000 Dataset [2], and were acquired with a variety of dermatoscope types, from all anatomic sites (excluding mucosa and nails), from a historical sample of patients presented for skin cancer screening, from several different institutions. Images were collected with approval of the Ethics Review Committee of University of Queensland (Protocol-No. 2017001223) and Medical University of Vienna (Protocol-No. 1804/2017).\n",
        "\n",
        "There are 7 classes:\n",
        "\n",
        "- MEL: “Melanoma” diagnosis confidence\n",
        "- NV: “Melanocytic nevus” diagnosis confidence\n",
        "- BCC: “Basal cell carcinoma” diagnosis confidence\n",
        "- AKIEC: “Actinic keratosis / Bowen’s disease (intraepithelial carcinoma)” diagnosis confidence\n",
        "- BKL: “Benign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis)” diagnosis confidence\n",
        "- DF: “Dermatofibroma” diagnosis confidence\n",
        "- VASC: “Vascular lesion” diagnosis confidence\n",
        "\n",
        "The distribution of disease states represent a modified “real world” setting whereby there are more benign lesions than malignant lesions, but an over-representation of malignancies.\n",
        "\n",
        "Here are some examples (taken from the ISIC2018 website):\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*le3-EQ-rpTLKtgB4G8jKkw.png\">\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "[1] Noel Codella, Veronica Rotemberg, Philipp Tschandl, M. Emre Celebi, Stephen Dusza, David Gutman, Brian Helba, Aadi Kalloo, Konstantinos Liopyris, Michael Marchetti, Harald Kittler, Allan Halpern: “Skin Lesion Analysis Toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC)”, 2018; https://arxiv.org/abs/1902.03368\n",
        "\n",
        "[2] Tschandl, P., Rosendahl, C. & Kittler, H. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Sci. Data 5, 180161 doi:10.1038/sdata.2018.161 (2018).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQb2NgWuDgi5"
      },
      "outputs": [],
      "source": [
        "!pip install torch-xla pytorch-lightning torch==2.3.0 torchvision lightning numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## Download and parse the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE32pdTCdWJf"
      },
      "outputs": [],
      "source": [
        "!wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Training_Input.zip\n",
        "!unzip ISIC2018_Task3_Training_Input.zip\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Training_GroundTruth.zip\n",
        "!unzip ISIC2018_Task3_Training_GroundTruth.zip\n",
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paPAwAjWhH6V"
      },
      "outputs": [],
      "source": [
        "# Define directories\n",
        "data_dir = pathlib.Path(\"data/\")\n",
        "input_dir = pathlib.Path(\"ISIC2018_Task3_Training_Input\")\n",
        "ground_truth_file = \"ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\"\n",
        "\n",
        "# Read ground truth and prepare class folders\n",
        "with open(ground_truth_file) as f:\n",
        "    header = f.readline().strip().split(\",\")\n",
        "\n",
        "    # Create class directories\n",
        "    for dir_class in header[1:]:  # Skip the first column (image ID)\n",
        "        class_dir = data_dir / dir_class\n",
        "        class_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Process each image in the ground truth file\n",
        "with open(ground_truth_file) as f:\n",
        "    next(f)  # Skip the header\n",
        "    for row in tqdm(f, desc=\"Organizing images\"):\n",
        "        row = row.strip().split(\",\")\n",
        "        image_id = row[0]\n",
        "        labels = row[1:]\n",
        "\n",
        "        src = input_dir / f\"{image_id}.jpg\"\n",
        "        if not src.exists():  # Skip if the source file does not exist\n",
        "            continue\n",
        "\n",
        "        for idx, label in enumerate(labels):\n",
        "            if label == \"1.0\":  # Only process relevant labels\n",
        "                dst = data_dir / header[idx + 1] / f\"{image_id}.jpg\"  # Class-specific directory\n",
        "                os.rename(src, dst)  # Move the file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpmywIlsVrVx"
      },
      "source": [
        "After downloading, you should now have a copy of the dataset available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbtTDYhOHZb6"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyDNn9MbIzfT"
      },
      "source": [
        "## Create a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqiK_AGI086"
      },
      "source": [
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H74l2DoDI2XD"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l-RVPmihH6V"
      },
      "outputs": [],
      "source": [
        "# Define data augmentation and preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_height, img_width)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaz3CbGDhH6V"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data_dir = \"data/\"\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwfduRkKhH6V"
      },
      "outputs": [],
      "source": [
        "# Split into training and validation datasets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iYRRfTghH6V"
      },
      "outputs": [],
      "source": [
        "# Define DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s66wJzWuhH6V"
      },
      "outputs": [],
      "source": [
        "# Display a random image from the dataset\n",
        "class_names = dataset.classes\n",
        "def show_random_image(dataset):\n",
        "    idx = random.randint(0, len(dataset) - 1)\n",
        "    print(idx)\n",
        "    image, label = dataset[idx]\n",
        "    plt.imshow(image.permute(1, 2, 0).numpy() * 0.5 + 0.5)  # Unnormalize\n",
        "    plt.title(f\"Label: {class_names[label]}\")\n",
        "    plt.show()\n",
        "\n",
        "show_random_image(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy8-91nGhH6V"
      },
      "outputs": [],
      "source": [
        "class MelanomaClassifier(pl.LightningModule):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MelanomaClassifier, self).__init__()\n",
        "        # Convolutional layers with fewer filters\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)  # Fewer filters: 16\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)  # Fewer filters: 32\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Additional layer for feature extraction\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Global average pooling to reduce dimensions\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layers with fewer neurons\n",
        "        self.fc1 = nn.Linear(64, 64)  # Reduced drastically due to global pooling\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional and pooling layers\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # Global average pooling\n",
        "        x = self.global_avg_pool(x)\n",
        "\n",
        "        # Flatten for the fully connected layers\n",
        "        x = torch.flatten(x, 1)  # (Batch size, Channels)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, labels = batch\n",
        "        outputs = self(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, labels = batch\n",
        "        outputs = self(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        acc = (preds == labels).float().mean()\n",
        "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        # Return logits for predictions\n",
        "        inputs, _ = batch  # Ignore labels during prediction\n",
        "        return self(inputs)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzPj6cZnhH6W"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "num_classes = len(class_names)\n",
        "model = MelanomaClassifier(num_classes=num_classes)\n",
        "\n",
        "# Initialize Trainer to use only CPU\n",
        "trainer = Trainer(\n",
        "    max_epochs=5,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.fit(model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "num_classes = len(dataset.classes)  # Replace with the number of classes\n",
        "model = MelanomaClassifier(num_classes=num_classes)\n",
        "\n",
        "# Load trained model (if already trained)\n",
        "# model = MelanomaClassifier.load_from_checkpoint(\"path/to/checkpoint.ckpt\")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(accelerator=\"cpu\", devices=1, max_epochs=10)\n",
        "\n",
        "# Predict on the validation set\n",
        "predictions = trainer.predict(model, dataloaders=val_loader)\n",
        "\n",
        "# Combine predictions into a single tensor\n",
        "predictions = torch.cat(predictions)\n",
        "\n",
        "# Print or inspect predictions\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "FoD-imASnxFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert logits to probabilities\n",
        "probabilities = torch.softmax(predictions, dim=1)\n",
        "\n",
        "# Get predicted class labels\n",
        "predicted_labels = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "# Display predictions\n",
        "print(\"Predicted probabilities:\", probabilities)\n",
        "print(\"Predicted labels:\", predicted_labels)\n"
      ],
      "metadata": {
        "id": "eRL6hwfCny7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Predict on the validation set\n",
        "predictions = trainer.predict(model, dataloaders=val_loader)\n",
        "\n",
        "# Combine predictions into a single tensor\n",
        "predictions = torch.cat(predictions)\n",
        "\n",
        "# Convert logits to probabilities and labels\n",
        "probabilities = torch.softmax(predictions, dim=1)\n",
        "predicted_labels = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "# Retrieve true labels and input images\n",
        "val_images = []\n",
        "val_labels = []\n",
        "\n",
        "for batch in val_loader:\n",
        "    inputs, labels = batch\n",
        "    val_images.append(inputs)\n",
        "    val_labels.append(labels)\n",
        "\n",
        "val_images = torch.cat(val_images)\n",
        "val_labels = torch.cat(val_labels)\n"
      ],
      "metadata": {
        "id": "eHjlMhb2oCvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predictions(images, true_labels, predicted_labels, probabilities, class_names, num_images=5):\n",
        "    \"\"\"Displays a few predictions with their probabilities.\"\"\"\n",
        "    plt.figure(figsize=(15, num_images * 3))\n",
        "    for i in range(num_images):\n",
        "        ax = plt.subplot(1, num_images, i + 1)\n",
        "        img = images[i].permute(1, 2, 0).numpy() * 0.5 + 0.5  # Unnormalize\n",
        "        plt.imshow(img)\n",
        "        true_label = class_names[true_labels[i].item()]\n",
        "        predicted_label = class_names[predicted_labels[i].item()]\n",
        "        confidence = probabilities[i][predicted_labels[i]].item()\n",
        "        plt.title(f\"True: {true_label}\\nPred: {predicted_label}\\nConf: {confidence:.2f}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display predictions for the first few images\n",
        "class_names = dataset.classes  # Get class names from the dataset\n",
        "show_predictions(\n",
        "    images=val_images[:5],\n",
        "    true_labels=val_labels[:5],\n",
        "    predicted_labels=predicted_labels[:5],\n",
        "    probabilities=probabilities[:5],\n",
        "    class_names=class_names\n",
        ")\n"
      ],
      "metadata": {
        "id": "fOSaK0sZoCtg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Melanoma_CNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}